summary(lm(Gain ~ Gender + URM_Status, df.MBT.2L))
df.MBT.3L <- Load.Clean.Data(assessment = 'MBT', RM = TRUE)
summary(lmer(Score ~ Time*(Gender + URM_Status) + (1 | Student_ID), df.MBT.3L))
df.MBT.2L <- Load.Clean.Data(assessment = 'MBT')
summary(lm(Gain ~ Gender, df.MBT.2L))
df.MBT.3L <- Load.Clean.Data(assessment = 'MBT', RM = TRUE)
summary(lmer(Score ~ Time*Gender + (1 | Student_ID), df.MBT.3L))
df.MBT.2L <- Load.Clean.Data(assessment = 'MBT')
summary(lm(Gain ~ Gender + URM_Status, df.MBT.2L))
df.MBT.3L <- Load.Clean.Data(assessment = 'MBT', RM = TRUE)
summary(lmer(Score ~ Time*Gender + URM_Status + (1 | Student_ID), df.MBT.3L))
df.MBT.2L <- Load.Clean.Data(assessment = 'MBT')
summary(lm(Gain ~ Gender, df.MBT.2L))
df.MBT.3L <- Load.Clean.Data(assessment = 'MBT', RM = TRUE)
summary(lmer(Score ~ Time*Gender + (1 | Student_ID), df.MBT.3L))
df.MBT.OLS <- Load.Clean.Data(assessment = 'MBT')
summary(lm(Gain ~ Gender, df.MBT.OLS))
df.MBT.RM <- Load.Clean.Data(assessment = 'MBT', RM = TRUE)
summary(lmer(Score ~ Time*Gender + (1 | Student_ID), df.MBT.RM))
library(data.table)
library(tidyverse)
library(broom)
library(broom.mixed)
library(lmerTest)
library(reshape2)
library(mvtnorm)
library(MASS)
library(lavaan)
library(sem)
library(semPlot)
library(forecast)
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-1, 1, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 2 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 2)')
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-1, 1, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 2 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
lm(post ~ pre, df))
summary(lm(post ~ pre, generate.data(pear.r = 0.5)))
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-1, 1, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 1 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 2)')
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-1, 1, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 1 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 1)')
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-1, 1, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 5 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 1)')
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-2, 1, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 5 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 1)')
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-2, 2, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 5 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 1)')
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-5, 5, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 5 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 1)')
summary(lavaan::sem(mod, generate.data(0.5)))
mod <- '
summary(lavaan::sem(mod, generate.data(0.5)))
summary(lavaan::sem(mod, generate.data(0.5)))
summary(lavaan::sem(mod, generate.data(0.5)))
library(data.table)
library(tidyverse)
library(broom)
library(broom.mixed)
library(lmerTest)
library(reshape2)
library(mvtnorm)
library(MASS)
library(lavaan)
library(sem)
library(semPlot)
library(forecast)
mod <- '
summary(lavaan::sem(mod, generate.data(0.5)))
cors <- seq(0, 1, by = 0.05)
mod <- '
pre ~ ability
post ~ pre
'
summary(lavaan::sem(mod, generate.data(0.5)))
# two stage least sqaures applied
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(tsls(post ~ pre,
~ ability,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
cors <- seq(0, 1, by = 0.05)
mod <- '
pre ~ ability
post ~ pre
'
summary(lavaan::sem(mod, generate.data(0.5)))
# two stage least sqaures applied
#coefs = sapply(cors, function(x) mean(replicate(n = 100,
#                                               expr = coef(tsls(post ~ pre,
#                                                               ~ ability,
#                                                              generate.data(pear.r = x)))[2])))
#plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
#     ylab = 'coefficient on pre (truth = 2)')
summary(lavaan::sem(mod, generate.data(0.5), fit.measures = TRUE))
summary(lavaan::sem(mod, generate.data(0.5), fitmeasures = TRUE))
summary(lavaan::sem(mod, generate.data(0.5), fit.measure = TRUE))
summary(lavaan::sem(mod, generate.data(0.5)), fit.measure = TRUE)
summary(lavaan::sem(mod, generate.data(0.5)), fit.measure = TRUE, standardized = TRUE)
cors <- seq(0, 1, by = 0.05)
mod <- '
pre ~ ability
post ~ pre
'
set.seed(11)
summary(lavaan::sem(mod, generate.data(0.5)), fit.measure = TRUE, standardized = TRUE)
# two stage least sqaures applied
#coefs = sapply(cors, function(x) mean(replicate(n = 100,
#                                               expr = coef(tsls(post ~ pre,
#                                                               ~ ability,
#                                                              generate.data(pear.r = x)))[2])))
#plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
#     ylab = 'coefficient on pre (truth = 2)')
cors <- seq(0, 1, by = 0.05)
mod <- '
pre ~ ability
post ~ pre
'
set.seed(11)
summary(lavaan::sem(mod, generate.data(0.5)), fit.measure = TRUE, standardized = TRUE)
# two stage least sqaures applied
#coefs = sapply(cors, function(x) mean(replicate(n = 100,
#                                               expr = coef(tsls(post ~ pre,
#                                                               ~ ability,
#                                                              generate.data(pear.r = x)))[2])))
#plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
#     ylab = 'coefficient on pre (truth = 2)')
cors <- seq(0, 1, by = 0.05)
mod <- '
pre ~ ability
post ~ pre
'
set.seed(11)
summary(lavaan::sem(mod, generate.data(0.1)), fit.measure = TRUE, standardized = TRUE)
# two stage least sqaures applied
#coefs = sapply(cors, function(x) mean(replicate(n = 100,
#                                               expr = coef(tsls(post ~ pre,
#                                                               ~ ability,
#                                                              generate.data(pear.r = x)))[2])))
#plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
#     ylab = 'coefficient on pre (truth = 2)')
cors <- seq(0, 1, by = 0.05)
mod <- '
pre ~ ability
post ~ pre
'
set.seed(11)
summary(lavaan::sem(mod, generate.data(0)), fit.measure = TRUE, standardized = TRUE)
# two stage least sqaures applied
#coefs = sapply(cors, function(x) mean(replicate(n = 100,
#                                               expr = coef(tsls(post ~ pre,
#                                                               ~ ability,
#                                                              generate.data(pear.r = x)))[2])))
#plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
#     ylab = 'coefficient on pre (truth = 2)')
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-5, 5, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 5 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ ability,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 1)')
n = 800
generate.data <- function(pear.r){
# create correlated errors on the pre and post tests
cor.errors <- mvtnorm::rmvnorm(n = n, mean = c(0,0), sigma = matrix(c(1, pear.r, pear.r,
1), ncol=2))
# create ability variable that is uniformly distributed
ability <- seq(-5, 5, length.out = n)
pre <- ability + cor.errors[, 1] # pre is related to unobervable ability
# postscore is equal to twice pre score with some measurement error.
# These are two meausurable variables.
post <- 5 * pre + cor.errors[, 2]
df <- data.frame(ability, pre, post)
return(df)
}
cors <- seq(0, 1, by = 0.05)
coefs = sapply(cors, function(x) mean(replicate(n = 100,
expr = coef(lm(post ~ pre + ability,
generate.data(pear.r = x)))[2])))
plot(cors, coefs, xlab = 'correlation between pre and post measurement errors',
ylab = 'coefficient on pre (truth = 1)')
library(data.table)
library(tidyverse)
library(broom)
library(lmerTest)
library(mice)
library(miceadds)
library(MuMIn)
library(stargazer)
library(lattice)
library(simr)
library(car)
Load.Clean.Data <- function(File = 'C:/Users/Cole/Documents/GRA_Summer2019/MasterDiagnosticDataConstruction/MasterData.csv',
assessment, impute = FALSE) {
df <- fread(File)
if(impute){
vars <- c('Class_Standing', 'Gender', 'URM_Status', 'First_Gen_Status', 'GPA', 'AP_Calculus_AB', 'AP_Calculus_BC', 'ACT_SAT_Math_Percentile', 'PreScores', 'PostScores', 'Season', 'Sequence', 'Course_Content', 'Class')
df.assessment <- df[Assessment == assessment]
# df.assessment <- df[Assessment == assessment & (!is.na(PreScores) | !is.na(PostScores))]
print(nrow(df.assessment))
} else {
vars <- c('Class_Standing', 'Gender', 'URM_Status', 'First_Gen_Status', 'AP_Calculus_AB', 'AP_Calculus_BC',
'ACT_SAT_Math_Percentile', 'PreScores', 'PostScores', 'Season', 'Sequence', 'Course_Content', 'Class')
df.assessment <- df[Assessment == assessment & (!is.na(PreScores) & !is.na(PostScores))]
}
df.assessment <- df.assessment %>%
select(vars) %>%
mutate(Class_Standing = relevel(as.factor(case_when(
Class_Standing == 'Fresh' ~ 'FY',
Class_Standing == 'Sophomore' | Class_Standing == 'Junior' | Class_Standing == 'Senior' ~ 'BFY',
TRUE ~ NA_character_
)), ref = 'FY'),
Gender = relevel(as.factor(Gender), ref = 'M'),
URM_Status = relevel(as.factor(URM_Status), ref = 'Majority'),
First_Gen_Status = relevel(as.factor(First_Gen_Status), ref = 'ContGen'),
AP_Calculus_AB = relevel(as.factor(AP_Calculus_AB), ref = 'NotTaken'),
AP_Calculus_BC = relevel(as.factor(AP_Calculus_BC), ref = 'NotTaken'),
Season = relevel(as.factor(Season), ref = 'FA'),
Sequence = relevel(as.factor(Sequence), ref = 'Engineering'),
Course_Content = as.factor(Course_Content),
Class = as.factor(Class),
ACT_SAT_Math_Percentile = c(scale(ACT_SAT_Math_Percentile, scale = TRUE)),
PreScores = c(scale(PreScores, scale = TRUE)),
PostScores = c(scale(PostScores, scale = TRUE)))
if(impute){
levels(df.assessment$Class) <- 1:length(levels(df.assessment$Class))
df.assessment$Class <- as.numeric(df.assessment$Class)
Frac.Missing <- round(sum(is.na(df.assessment$PreScores) |
is.na(df.assessment$PostScores))/nrow(df.assessment) * 100)
print(Frac.Missing)
ini <- mice(df.assessment, maxit = 0)
predM <- ini$predictorMatrix
iniM <- ini$method
predM[, 'Class'] <- -2
# print(iniM)
iniM <- c('', '', '', '', '', '', '', '', '2l.pmm', '2l.pmm', '', '', '', '')
# iniM <- c('', '', '', '', '', '', '', '2l.pmm', '2l.pmm', '', '', '', '')
set.seed(11)
imp.dat <- mice(df.assessment, m = Frac.Missing, pred = predM, met = iniM, print = FALSE)
return(imp.dat)
}
return(df.assessment)
}
Do.Regressions <- function(dat, assessment) {
fit0 <- lmer(PostScores ~ (1 | Class), dat)
print(summary(fit0))
print(r.squaredGLMM(fit0))
print(AIC(fit0))
fit1a <- lmer(PostScores ~ Gender + (1 | Class), dat)
print(summary(fit1a))
print(r.squaredGLMM(fit1a))
print(AIC(fit1a))
fit1b <- lmer(PostScores ~ URM_Status + (1 | Class), dat)
print(summary(fit1b))
print(r.squaredGLMM(fit1b))
print(AIC(fit1b))
fit1c <- lmer(PostScores ~ Class_Standing + (1 | Class), dat)
print(summary(fit1c))
print(r.squaredGLMM(fit1c))
print(AIC(fit1c))
fit1d <- lmer(PostScores ~ First_Gen_Status + (1 | Class), dat)
print(summary(fit1d))
print(r.squaredGLMM(fit1d))
print(AIC(fit1d))
fit2 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + (1 | Class), dat)
print(summary(fit2))
print(r.squaredGLMM(fit2))
print(AIC(fit2))
fit3 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + (1 | Class), dat)
print(summary(fit3))
print(r.squaredGLMM(fit3))
print(AIC(fit3))
fit4 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + (1 | Class), dat)
print(summary(fit4))
print(r.squaredGLMM(fit4))
print(AIC(fit4))
if(assessment == 'PLIC' | assessment == 'ECLASS'){
fit5 <- lmer(PostScores - PreScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), dat, na.action = "na.fail")
#fit6 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + Season + Sequence + Course_Content + (1 | Class), dat)
} else {
fit5 <- lmer(PostScores - PreScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + (1 | Class), dat, na.action = "na.fail")
#fit6 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + Season + Sequence + (1 | Class), dat)
}
print(summary(fit5))
print(r.squaredGLMM(fit5))
print(AIC(fit5))
#fit6 <- get.models(dredge(fit5, rank = 'AIC'), subset = 1)[[1]]
#print(summary(fit6))
#print(r.squaredGLMM(fit6))
#print(AIC(fit6))
class(fit0) <- "lmerMod"
class(fit1a) <- "lmerMod"
class(fit1b) <- "lmerMod"
class(fit1c) <- "lmerMod"
class(fit1d) <- "lmerMod"
class(fit2) <- "lmerMod"
class(fit3) <- "lmerMod"
class(fit4) <- "lmerMod"
class(fit5) <- "lmerMod"
#class(fit6) <- "lmerMod"
#stargazer(fit0, fit1a, fit1b, fit1c, fit1d, fit2, fit3, fit4, fit5, fit6, star.cutoffs = c(0.05, 0.01, 0.001), intercept.bottom = FALSE, out = paste(assessment, '.tex'), intercept.top = TRUE, omit.stat = 'all')
# dat$resid <- resid(fit5)
# dat$resid.abs <- abs(dat$resid)
# dat$resid.abs.2 <- dat$resid.abs^2
# dat$pred <- fitted(fit5)
Coefs.summary <- rbind(rbind(tidy(fit1a), tidy(fit1b), tidy(fit1c), tidy(fit1d)) %>% mutate(Model = 1), tidy(fit2) %>% mutate(Model = 2), tidy(fit3) %>% mutate(Model = 3), tidy(fit5) %>% mutate(Model = 5))
return(list("model" = fit5, "dataframe" = dat, 'Coefs' = Coefs.summary))
}
df.CSEM <- Load.Clean.Data(assessment = 'CSEM')
df.CSEM.fit5 <- Do.Regressions(df.CSEM, assessment = 'CSEM')
plot(df.CSEM.fit5$model, xlab = 'Fitted values', ylab = 'Residuals')
CSEM.Coefs <- df.CSEM.fit5$Coefs
vif(df.CSEM.fit5$model)
# boxplot(resid.abs.2 ~ Class, df.CSEM.fit5$dataframe)
# anova(lm(resid.abs.2 ~ Class, data = df.CSEM.fit5$dataframe))
qqmath(df.CSEM.fit5$model)
library(pwr)
library(WebPower)
library(tidyverse)
library(reshape2)
power.vec <- seq(0.13, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.8)
Power.func <- function(effect, power){
out <- wp.regression(p1 = 13, p2 = 9, f2 = effect, alpha = 0.05, power = power)
return(out$n)
}
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02)) %>%#,
#N2 = sapply(power.vec, Power.func, effect = 0.15),
#N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
ggplot(df, aes(x = value, y = Power, color = variable)) +
#geom_point() +
theme_classic() +
geom_line(size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[(df$Power == 0.8) & (df$variable == 'N1'), 'value'], linetype = 3, color = 'black', size = 1)
#p.out <- pwr.f2.test(u = 8, f2 = 0.02, sig.level = 0.05, power = 0.8)
#p.out$v + p.out$u + 1
power.vec <- seq(0.13, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.8)
Power.func <- function(effect, power){
out <- wp.regression(p1 = 13, p2 = 9, f2 = effect, alpha = 0.05, power = power)
return(out$n)
}
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02)) %>%#,
#N2 = sapply(power.vec, Power.func, effect = 0.15),
#N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
ggplot(df, aes(x = value, y = Power)) +
#geom_point() +
theme_classic() +
geom_line(size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[(df$Power == 0.8) & (df$variable == 'N1'), 'value'], linetype = 3, color = 'black', size = 1)
#p.out <- pwr.f2.test(u = 8, f2 = 0.02, sig.level = 0.05, power = 0.8)
#p.out$v + p.out$u + 1
ggplot(df, aes(x = value, y = Power)) +
#geom_point() +
theme_classic() +
geom_line(size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[(df$Power == 0.8) & (df$variable == 'N1'), 'value'], linetype = 3, color = 'black', size = 1)
