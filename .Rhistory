qqmath(df.CSEM.fit5$model)
library(pwr)
library(WebPower)
library(tidyverse)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.95)$n
power.vec <- seq(0.06, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.95)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N = sapply(power.vec, function (x) {
out <- wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = x)
return(out$n)}))
ggplot(df, aes(x = N, y = Power)) +
#geom_point() +
theme_classic() +
geom_line(color = 'black', size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[power.vec == 0.8, c('N')], linetype = 3, color = 'blue', size = 1)
#p.out <- pwr.f2.test(u = 8, f2 = 0.02, sig.level = 0.05, power = 0.8)
#p.out$v + p.out$u + 1
power.vec <- seq(0.06, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.95)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N = sapply(power.vec, function (x) {
out <- wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = x)
return(out$n)}))
ggplot(df, aes(x = N, y = Power)) +
#geom_point() +
theme_classic() +
geom_line(color = 'black', size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[power.vec == 0.8, c('N')], linetype = 3, color = 'blue', size = 1)
#p.out <- pwr.f2.test(u = 8, f2 = 0.02, sig.level = 0.05, power = 0.8)
#p.out$v + p.out$u + 1
power.vec <- seq(0.06, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.8)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N = sapply(power.vec, function (x) {
out <- wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = x)
return(out$n)}))
ggplot(df, aes(x = N, y = Power)) +
#geom_point() +
theme_classic() +
geom_line(color = 'black', size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[power.vec == 0.8, c('N')], linetype = 3, color = 'blue', size = 1)
#p.out <- pwr.f2.test(u = 8, f2 = 0.02, sig.level = 0.05, power = 0.8)
#p.out$v + p.out$u + 1
df
power.vec <- seq(0.06, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.8)
Power.func <- function(effect, power){
out <- wp.regression(p1 = 13, p2 = 9, f2 = effect, alpha = 0.05, power = x)
return(out$n)
}
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N = sapply(power.vec, Power.func, f2 = 0.02))
power.vec <- seq(0.06, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.8)
Power.func <- function(effect, power){
out <- wp.regression(p1 = 13, p2 = 9, f2 = effect, alpha = 0.05, power = x)
return(out$n)
}
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N = sapply(power.vec, Power.func, effect = 0.02))
power.vec <- seq(0.06, 0.99, 0.01)
wp.regression(p1 = 13, p2 = 9, f2 = 0.02, alpha = 0.05, power = 0.8)
Power.func <- function(effect, power){
out <- wp.regression(p1 = 13, p2 = 9, f2 = effect, alpha = 0.05, power = power)
return(out$n)
}
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N = sapply(power.vec, Power.func, effect = 0.02))
ggplot(df, aes(x = N, y = Power)) +
#geom_point() +
theme_classic() +
geom_line(color = 'black', size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[power.vec == 0.8, c('N')], linetype = 3, color = 'blue', size = 1)
#p.out <- pwr.f2.test(u = 8, f2 = 0.02, sig.level = 0.05, power = 0.8)
#p.out$v + p.out$u + 1
library(reshape2)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.07, 0.99, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.3, 0.7, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.2, 0.8, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.05, 0.95, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.07, 0.93, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.09, 0.91, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.1, 0.9, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.1, 0.9, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.2, 0.8, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.15, 0.85, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.12, 0.88, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.13, 0.87, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.1, 0.87, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.13, 0.9, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.13, 0.95, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
power.vec <- seq(0.13, 0.99, 0.01)
#wp.regression(p1 = 8, p2 = 2, f2 = 0.02, alpha = 0.05, power = 0.99)
df <- data.frame(Power = power.vec, N1 = sapply(power.vec, Power.func, effect = 0.02),
N2 = sapply(power.vec, Power.func, effect = 0.15),
N3 = sapply(power.vec, Power.func, effect = 0.35)) %>%
melt(., id.vars = 'Power')
df
ggplot(df, aes(x = value, y = Power, color = variable)) +
#geom_point() +
theme_classic() +
geom_line(size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[(df$Power == 0.8) & (df$variable == N1), 'value'], linetype = 3, color = 'black', size = 1)
ggplot(df, aes(x = value, y = Power, color = variable)) +
#geom_point() +
theme_classic() +
geom_line(size = 1) +
labs(x = 'Sample size') +
geom_vline(xintercept = df[(df$Power == 0.8) & (df$variable == 'N1'), 'value'], linetype = 3, color = 'black', size = 1)
install.packages("nlmeU")
library(data.table)
library(tidyverse)
library(lmerTest)
library(MuMIn)
library(stargazer)
library(lattice)
library(nlmeU)
Load.Clean.Data <- function(File = 'C:/Users/Cole/Documents/GRA_Summer2019/MasterDiagnosticDataConstruction/MasterData.csv',
assessment) {
df <- fread(File)
df.assessment <- df[Assessment == assessment & (!is.na(PreScores) & !is.na(PostScores))] %>%
select(Class_Standing, Gender, URM_Status, First_Gen_Status, AP_Calculus_AB, AP_Calculus_BC, ACT_SAT_Math_Percentile, PreScores, PostScores, Season, Sequence, Course_Content, Class) %>%
mutate(Class_Standing = relevel(as.factor(case_when(
Class_Standing == 'Fresh' ~ 'FY',
Class_Standing == 'Sophomore' | Class_Standing == 'Junior' | Class_Standing == 'Senior' ~ 'BFY',
TRUE ~ NA_character_
)), ref = 'FY'),
Gender = relevel(as.factor(Gender), ref = 'M'),
URM_Status = relevel(as.factor(URM_Status), ref = 'Majority'),
First_Gen_Status = relevel(as.factor(First_Gen_Status), ref = 'ContGen'),
AP_Calculus_AB = relevel(as.factor(AP_Calculus_AB), ref = 'NotTaken'),
AP_Calculus_BC = relevel(as.factor(AP_Calculus_BC), ref = 'NotTaken'),
Season = relevel(as.factor(Season), ref = 'FA'),
Sequence = relevel(as.factor(Sequence), ref = 'Engineering'),
Course_Content = as.factor(Course_Content),
Class = as.factor(Class),
ACT_SAT_Math_Percentile = c(scale(ACT_SAT_Math_Percentile, scale = TRUE)),
PreScores = c(scale(PreScores, scale = TRUE)),
PostScores = c(scale(PostScores, scale = TRUE))) %>%
filter(!is.na(URM_Status) & !is.na(Class_Standing) & !is.na(ACT_SAT_Math_Percentile))
return(df.assessment)
}
Do.Regressions <- function(dat, assessment) {
fit0 <- lmer(PostScores ~ (1 | Class), dat)
print(summary(fit0))
print(r.squaredGLMM(fit0))
fit1a <- lmer(PostScores ~ Gender + (1 | Class), dat)
print(summary(fit1a))
print(r.squaredGLMM(fit1a))
fit1b <- lmer(PostScores ~ URM_Status + (1 | Class), dat)
print(summary(fit1b))
print(r.squaredGLMM(fit1b))
fit1c <- lmer(PostScores ~ Class_Standing + (1 | Class), dat)
print(summary(fit1c))
print(r.squaredGLMM(fit1c))
fit1d <- lmer(PostScores ~ First_Gen_Status + (1 | Class), dat)
print(summary(fit1d))
print(r.squaredGLMM(fit1d))
fit2 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + (1 | Class), dat)
print(summary(fit2))
print(r.squaredGLMM(fit2))
fit3 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + (1 | Class), dat)
print(summary(fit3))
print(r.squaredGLMM(fit3))
fit4 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + (1 | Class), dat)
print(summary(fit4))
print(r.squaredGLMM(fit4))
if(assessment == 'PLIC' | assessment == 'ECLASS'){
fit5 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), dat)
} else {
fit5 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + (1 | Class), dat)
}
print(summary(fit5))
print(r.squaredGLMM(fit5))
class(fit0) <- "lmerMod"
class(fit1a) <- "lmerMod"
class(fit1b) <- "lmerMod"
class(fit1c) <- "lmerMod"
class(fit1d) <- "lmerMod"
class(fit2) <- "lmerMod"
class(fit3) <- "lmerMod"
class(fit4) <- "lmerMod"
class(fit5) <- "lmerMod"
stargazer(fit0, fit1a, fit1b, fit1c, fit1d, fit2, fit3, fit4, fit5, star.cutoffs = c(0.05, 0.01, 0.001), intercept.bottom = FALSE, out = paste(assessment, '.tex'), intercept.top = TRUE, omit.stat = 'all')
dat$resid <- resid(fit5)
dat$resid.abs <- abs(dat$resid)
dat$resid.abs.2 <- dat$resid.abs^2
dat$pred <- fitted(fit5)
return(list("model" = fit5, "dataframe" = dat))
}
library(data.table)
library(tidyverse)
library(lmerTest)
library(MuMIn)
library(stargazer)
library(lattice)
library(nlmeU)
Load.Clean.Data <- function(File = 'C:/Users/Cole/Documents/GRA_Summer2019/MasterDiagnosticDataConstruction/MasterData.csv',
assessment) {
df <- fread(File)
df.assessment <- df[Assessment == assessment & (!is.na(PreScores) & !is.na(PostScores))] %>%
select(Class_Standing, Gender, URM_Status, First_Gen_Status, AP_Calculus_AB, AP_Calculus_BC, ACT_SAT_Math_Percentile, PreScores, PostScores, Season, Sequence, Course_Content, Class) %>%
mutate(Class_Standing = relevel(as.factor(case_when(
Class_Standing == 'Fresh' ~ 'FY',
Class_Standing == 'Sophomore' | Class_Standing == 'Junior' | Class_Standing == 'Senior' ~ 'BFY',
TRUE ~ NA_character_
)), ref = 'FY'),
Gender = relevel(as.factor(Gender), ref = 'M'),
URM_Status = relevel(as.factor(URM_Status), ref = 'Majority'),
First_Gen_Status = relevel(as.factor(First_Gen_Status), ref = 'ContGen'),
AP_Calculus_AB = relevel(as.factor(AP_Calculus_AB), ref = 'NotTaken'),
AP_Calculus_BC = relevel(as.factor(AP_Calculus_BC), ref = 'NotTaken'),
Season = relevel(as.factor(Season), ref = 'FA'),
Sequence = relevel(as.factor(Sequence), ref = 'Engineering'),
Course_Content = as.factor(Course_Content),
Class = as.factor(Class),
ACT_SAT_Math_Percentile = c(scale(ACT_SAT_Math_Percentile, scale = TRUE)),
PreScores = c(scale(PreScores, scale = TRUE)),
PostScores = c(scale(PostScores, scale = TRUE))) %>%
filter(!is.na(URM_Status) & !is.na(Class_Standing) & !is.na(ACT_SAT_Math_Percentile))
return(df.assessment)
}
Do.Regressions <- function(dat, assessment) {
fit0 <- lmer(PostScores ~ (1 | Class), dat)
print(summary(fit0))
print(r.squaredGLMM(fit0))
fit1a <- lmer(PostScores ~ Gender + (1 | Class), dat)
print(summary(fit1a))
print(r.squaredGLMM(fit1a))
fit1b <- lmer(PostScores ~ URM_Status + (1 | Class), dat)
print(summary(fit1b))
print(r.squaredGLMM(fit1b))
fit1c <- lmer(PostScores ~ Class_Standing + (1 | Class), dat)
print(summary(fit1c))
print(r.squaredGLMM(fit1c))
fit1d <- lmer(PostScores ~ First_Gen_Status + (1 | Class), dat)
print(summary(fit1d))
print(r.squaredGLMM(fit1d))
fit2 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + (1 | Class), dat)
print(summary(fit2))
print(r.squaredGLMM(fit2))
fit3 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + (1 | Class), dat)
print(summary(fit3))
print(r.squaredGLMM(fit3))
fit4 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + (1 | Class), dat)
print(summary(fit4))
print(r.squaredGLMM(fit4))
if(assessment == 'PLIC' | assessment == 'ECLASS'){
fit5 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), dat)
} else {
fit5 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + (1 | Class), dat)
}
print(summary(fit5))
print(r.squaredGLMM(fit5))
class(fit0) <- "lmerMod"
class(fit1a) <- "lmerMod"
class(fit1b) <- "lmerMod"
class(fit1c) <- "lmerMod"
class(fit1d) <- "lmerMod"
class(fit2) <- "lmerMod"
class(fit3) <- "lmerMod"
class(fit4) <- "lmerMod"
class(fit5) <- "lmerMod"
stargazer(fit0, fit1a, fit1b, fit1c, fit1d, fit2, fit3, fit4, fit5, star.cutoffs = c(0.05, 0.01, 0.001), intercept.bottom = FALSE, out = paste(assessment, '.tex'), intercept.top = TRUE, omit.stat = 'all')
dat$resid <- resid(fit5)
dat$resid.abs <- abs(dat$resid)
dat$resid.abs.2 <- dat$resid.abs^2
dat$pred <- fitted(fit5)
return(list("model" = fit5, "dataframe" = dat))
}
df.PLIC <- Load.Clean.Data(assessment = 'PLIC')
df.PLIC.fit5 <-  Do.Regressions(df.PLIC, assessment = 'PLIC')
plot(df.PLIC.fit5$model)
boxplot(resid.abs.2 ~ Class, df.PLIC.fit5$dataframe)
anova(lm(resid.abs.2 ~ Class, data = df.PLIC.fit5$dataframe))
qqmath(df.PLIC.fit5$model)
Pwr(df.PLIC.fit5$model)
Pwr.lme(df.PLIC.fit5$model)
install.packages("simr")
library(simr)
powerSim(df.PLIC.fit5$model)
powerSim(df.PLIC.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), df.PLIC.fit5$dataframe)), nsim = 100)
powerCurve(df.PLIC.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), df.PLIC.fit5$dataframe)), nsim = 100)
powerSim(df.PLIC.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), df.PLIC.fit5$dataframe)), nsim = 100)
df.MBT <- Load.Clean.Data(assessment = 'MBT')
df.MBT.fit5 <- Do.Regressions(df.MBT, assessment = 'MBT')
plot(df.MBT.fit5$model)
boxplot(resid.abs.2 ~ Class, df.MBT.fit5$dataframe)
anova(lm(resid.abs.2 ~ Class, data = df.MBT.fit5$dataframe))
qqmath(df.MBT.fit5$model)
powerSim(df.MBT.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), df.MBT.fit5$dataframe)), nsim = 100)
powerSim(df.MBT.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), df.MBT.fit5$dataframe)), nsim = 100)
powerSim(df.MBT.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + (1 | Class), df.MBT.fit5$dataframe)), nsim = 100)
powerSim(df.CSEM.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + (1 | Class), df.CSEM.fit5$dataframe)), nsim = 100)
df.CSEM <- Load.Clean.Data(assessment = 'CSEM')
df.CSEM.fit5 <- Do.Regressions(df.CSEM, assessment = 'CSEM')
powerSim(df.CSEM.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + (1 | Class), df.CSEM.fit5$dataframe)), nsim = 100)
df.ECLASS <- Load.Clean.Data(assessment = 'ECLASS')
df.ECLASS.fit5 <- Do.Regressions(df.ECLASS, assessment = 'ECLASS')
powerSim(df.ECLASS.fit5$model, test = compare(lmer(PostScores ~ PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), df.ECLASS.fit5$dataframe)), nsim = 100)
library(data.table)
library(tidyverse)
library(lmerTest)
library(MuMIn)
library(stargazer)
library(lattice)
library(simr)
Load.Clean.Data <- function(File = 'C:/Users/Cole/Documents/GRA_Summer2019/MasterDiagnosticDataConstruction/MasterData.csv',
assessment) {
df <- fread(File)
df.assessment <- df[Assessment == assessment & (!is.na(PreScores) & !is.na(PostScores))] %>%
select(Class_Standing, Gender, URM_Status, First_Gen_Status, AP_Calculus_AB, AP_Calculus_BC, ACT_SAT_Math_Percentile, PreScores, PostScores, Season, Sequence, Course_Content, Class) %>%
mutate(Class_Standing = relevel(as.factor(case_when(
Class_Standing == 'Fresh' ~ 'FY',
Class_Standing == 'Sophomore' | Class_Standing == 'Junior' | Class_Standing == 'Senior' ~ 'BFY',
TRUE ~ NA_character_
)), ref = 'FY'),
Gender = relevel(as.factor(Gender), ref = 'M'),
URM_Status = relevel(as.factor(URM_Status), ref = 'Majority'),
First_Gen_Status = relevel(as.factor(First_Gen_Status), ref = 'ContGen'),
AP_Calculus_AB = relevel(as.factor(AP_Calculus_AB), ref = 'NotTaken'),
AP_Calculus_BC = relevel(as.factor(AP_Calculus_BC), ref = 'NotTaken'),
Season = relevel(as.factor(Season), ref = 'FA'),
Sequence = relevel(as.factor(Sequence), ref = 'Engineering'),
Course_Content = as.factor(Course_Content),
Class = as.factor(Class),
ACT_SAT_Math_Percentile = c(scale(ACT_SAT_Math_Percentile, scale = TRUE)),
PreScores = c(scale(PreScores, scale = TRUE)),
PostScores = c(scale(PostScores, scale = TRUE))) %>%
filter(!is.na(URM_Status) & !is.na(Class_Standing) & !is.na(ACT_SAT_Math_Percentile))
return(df.assessment)
}
Do.Regressions <- function(dat, assessment) {
fit0 <- lmer(PostScores ~ (1 | Class), dat)
print(summary(fit0))
print(r.squaredGLMM(fit0))
fit1a <- lmer(PostScores ~ Gender + (1 | Class), dat)
print(summary(fit1a))
print(r.squaredGLMM(fit1a))
fit1b <- lmer(PostScores ~ URM_Status + (1 | Class), dat)
print(summary(fit1b))
print(r.squaredGLMM(fit1b))
fit1c <- lmer(PostScores ~ Class_Standing + (1 | Class), dat)
print(summary(fit1c))
print(r.squaredGLMM(fit1c))
fit1d <- lmer(PostScores ~ First_Gen_Status + (1 | Class), dat)
print(summary(fit1d))
print(r.squaredGLMM(fit1d))
fit2 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + (1 | Class), dat)
print(summary(fit2))
print(r.squaredGLMM(fit2))
fit3 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + (1 | Class), dat)
print(summary(fit3))
print(r.squaredGLMM(fit3))
fit4 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + (1 | Class), dat)
print(summary(fit4))
print(r.squaredGLMM(fit4))
if(assessment == 'PLIC' | assessment == 'ECLASS'){
fit5 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + Course_Content + (1 | Class), dat)
} else {
fit5 <- lmer(PostScores ~ Gender + URM_Status + Class_Standing + First_Gen_Status + PreScores + ACT_SAT_Math_Percentile + AP_Calculus_AB + AP_Calculus_BC + Season + Sequence + (1 | Class), dat)
}
print(summary(fit5))
print(r.squaredGLMM(fit5))
class(fit0) <- "lmerMod"
class(fit1a) <- "lmerMod"
class(fit1b) <- "lmerMod"
class(fit1c) <- "lmerMod"
class(fit1d) <- "lmerMod"
class(fit2) <- "lmerMod"
class(fit3) <- "lmerMod"
class(fit4) <- "lmerMod"
class(fit5) <- "lmerMod"
stargazer(fit0, fit1a, fit1b, fit1c, fit1d, fit2, fit3, fit4, fit5, star.cutoffs = c(0.05, 0.01, 0.001), intercept.bottom = FALSE, out = paste(assessment, '.tex'), intercept.top = TRUE, omit.stat = 'all')
dat$resid <- resid(fit5)
dat$resid.abs <- abs(dat$resid)
dat$resid.abs.2 <- dat$resid.abs^2
dat$pred <- fitted(fit5)
return(list("model" = fit5, "dataframe" = dat))
}
df.PLIC <- Load.Clean.Data(assessment = 'PLIC')
df.PLIC.fit5 <-  Do.Regressions(df.PLIC, assessment = 'PLIC')
plot(df.PLIC.fit5$model)
boxplot(resid.abs.2 ~ Class, df.PLIC.fit5$dataframe)
anova(lm(resid.abs.2 ~ Class, data = df.PLIC.fit5$dataframe))
qqmath(df.PLIC.fit5$model)
df.ECLASS <- Load.Clean.Data(assessment = 'ECLASS')
df.ECLASS.fit5 <- Do.Regressions(df.ECLASS, assessment = 'ECLASS')
plot(df.ECLASS.fit5$model)
boxplot(resid.abs.2 ~ Class, df.ECLASS.fit5$dataframe)
anova(lm(resid.abs.2 ~ Class, data = df.ECLASS.fit5$dataframe))
qqmath(df.ECLASS.fit5$model)
df.MBT <- Load.Clean.Data(assessment = 'MBT')
df.MBT.fit5 <- Do.Regressions(df.MBT, assessment = 'MBT')
plot(df.MBT.fit5$model)
boxplot(resid.abs.2 ~ Class, df.MBT.fit5$dataframe)
anova(lm(resid.abs.2 ~ Class, data = df.MBT.fit5$dataframe))
qqmath(df.MBT.fit5$model)
df.CSEM <- Load.Clean.Data(assessment = 'CSEM')
df.CSEM.fit5 <- Do.Regressions(df.CSEM, assessment = 'CSEM')
plot(df.CSEM.fit5$model)
boxplot(resid.abs.2 ~ Class, df.CSEM.fit5$dataframe)
anova(lm(resid.abs.2 ~ Class, data = df.CSEM.fit5$dataframe))
qqmath(df.CSEM.fit5$model)
Do.Simulated.Power <- function(model, var, fixed.eff, eff = -0.2, nsim = 1000){
fixef(model)[fixed.eff] <- eff
pow <- powerSim(model, test = fixed(var), progress = FALSE, nsim = nsim)
return(pow)
}
lapply(list(c('Gender', 'GenderF'), c('URM_Status', 'URM_StatusURM'), c('Class_Standing', 'Class_StandingBFY')), function (x) {
Do.Simulated.Power(model = df.PLIC.fit5$model, var = x[1], fixed.eff = x[2])
})
lapply(list(c('Gender', 'GenderF'), c('URM_Status', 'URM_StatusURM'), c('Class_Standing', 'Class_StandingBFY'), c('First_Gen_Status', 'First_Gen_StatusFirstGen')), function (x) {
Do.Simulated.Power(model = df.ECLASS.fit5$model, var = x[1], fixed.eff = x[2])
})
lapply(list(c('Gender', 'GenderF'), c('Class_Standing', 'Class_StandingBFY'), c('First_Gen_Status', 'First_Gen_StatusFirstGen')), function (x) {
Do.Simulated.Power(model = df.MBT.fit5$model, var = x[1], fixed.eff = x[2])
})
lapply(list(c('URM_Status', 'URM_StatusURM'), c('First_Gen_Status', 'First_Gen_StatusFirstGen')), function (x) {
Do.Simulated.Power(model = df.CSEM.fit5$model, var = x[1], fixed.eff = x[2])
})
